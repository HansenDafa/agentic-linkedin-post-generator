# multi_agent.py

import ollama
from prompts import generator_prompt, critic_prompt, refine_prompt, stylist_prompt, optimizer_prompt

GEN_MODEL = "llama3.2"
CRITIC_MODEL = "llama3.2:1b"
STYLE_MODEL = "llama3.2:1b"
OPTIMIZER_MODEL = "llama3.2"

def call_ollama(model, prompt):
    response = ollama.generate(model=model, prompt=prompt)
    return response['response'].strip()

def multi_agent_pipeline(entry, style="inspirational", iterations=2):
    log = []

    draft = call_ollama(GEN_MODEL, generator_prompt(entry))
    log.append("üîπ Initial draft:")
    log.append(draft)

    for i in range(iterations):
        log.append(f"üîÅ Iteration {i+1}: Critique + Improve")

        feedback = call_ollama(CRITIC_MODEL, critic_prompt(draft))
        log.append(f"üßê Critique:\n{feedback}")

        draft = call_ollama(GEN_MODEL, refine_prompt(draft, feedback))
        log.append(f"‚úçÔ∏è Revised:\n{draft}")

    # Final stylist + polish
    styled = call_ollama(STYLE_MODEL, stylist_prompt(draft, style))
    log.append(f"üé® Stylist applied ({style})")

    final = call_ollama(OPTIMIZER_MODEL, optimizer_prompt(styled, entry))
    log.append("üìä Optimized with hashtags + CTA")

    return {
        "log": log,
        "final": final
    }
